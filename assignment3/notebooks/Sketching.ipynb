{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count-Min Sketching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../data/capture20110811.pcap.netflow_43_.labeled'\n",
    "infected = '147.32.84.165'\n",
    "n = 10\n",
    "with open(data_file, \"r\") as ins:\n",
    "    lines = ins.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform sketching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define various values for the number of hash functions and their range\n",
    "ds = [50,200,25]\n",
    "ws = [500,1000,700]\n",
    "# run 10 iterations to average the run-time\n",
    "iterations = 10\n",
    "run_times = np.zeros([iterations,len(ds)])\n",
    "\n",
    "\n",
    "for it in range(iterations):\n",
    "    estimates = []\n",
    "    \n",
    "    for i in range(len(ds)):\n",
    "        d = ds[i]\n",
    "        w = ws[i]\n",
    "        total = 0\n",
    "        # dictionaries to facilitate IP to id translation and vice versa\n",
    "        ip_dict = {}\n",
    "        rev_ip_dict = {}\n",
    "\n",
    "        # initialize count min sketch as an array of zeros\n",
    "        cm = np.zeros((d,w))\n",
    "        k = 0\n",
    "\n",
    "        coefs = []\n",
    "        consts = []\n",
    "\n",
    "        # use the hash function from the slides\n",
    "        def hash_func(coef,const,base,value):\n",
    "            return (coef*value + const)%base\n",
    "\n",
    "        # start time recording\n",
    "        start = time.time()\n",
    "\n",
    "        # create independent hash functions by using a different coefficient and bias term for each\n",
    "        for j in range(d):\n",
    "            temp = random.randint(1,d)\n",
    "            while temp in coefs:\n",
    "                temp = random.randint(1,d)\n",
    "            coefs.append(temp)\n",
    "            temp = random.randint(1, d)\n",
    "            while temp in consts:\n",
    "                temp = random.randint(1,d)\n",
    "            consts.append(temp)\n",
    "\n",
    "\n",
    "        for line in lines:\n",
    "            parts = line.split()\n",
    "            ip_port_src = parts[4].split(':')\n",
    "            ip_src = ip_port_src[0]\n",
    "            \n",
    "            # if this is from our infected host\n",
    "            if ip_src == infected:\n",
    "                total += 1\n",
    "                ip_port_dst = parts[6].split(':')\n",
    "                dst_ip = ip_port_dst[0]\n",
    "                \n",
    "                # find the id of the IP\n",
    "                if dst_ip not in ip_dict.keys():\n",
    "                    ip_dict[dst_ip] = k\n",
    "                    rev_ip_dict[k] = dst_ip\n",
    "                    k += 1\n",
    "                temp = ip_dict[dst_ip]\n",
    "                # use the id to get a hash from each hash function and update the sketch\n",
    "                for j in range(d):\n",
    "                    col = hash_func(coefs[j], consts[j], w, temp)\n",
    "                    cm[j, col] = cm[j, col] + 1\n",
    "\n",
    "        # find the minimum value for each IP\n",
    "        A = np.zeros((k - 1, 1), dtype=np.int32)\n",
    "        for l in range(k - 1):\n",
    "            minimum = total\n",
    "            for j in range(d):\n",
    "                temp = cm[j][hash_func(coefs[j], consts[j], w, l)]\n",
    "                if temp < minimum:\n",
    "                    A[l] = temp\n",
    "                    minimum = temp\n",
    "\n",
    "        # find the 10 most frequent IPs\n",
    "        out = A.flatten()\n",
    "        res = np.argsort(out)\n",
    "        ips_estimated = []\n",
    "        counts = []\n",
    "\n",
    "        \n",
    "        # stop time recording\n",
    "        stop = time.time()\n",
    "        run_times[it][i] = stop - start\n",
    "        \n",
    "        for j in res[-10:]:\n",
    "            ips_estimated.append(rev_ip_dict[j])\n",
    "            counts.append(round(out[j]/total,3))\n",
    "        \n",
    "\n",
    "        # store results for evaluation\n",
    "        estimates.append({\n",
    "            'ips': np.array(ips_estimated),\n",
    "            'freqs': np.array(counts),\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out true top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the actual counts of each IP\n",
    "ips = {}\n",
    "infected_flow_count = 0\n",
    "n = 10\n",
    "with open(\"../data/capture20110811.pcap.netflow_43_.labeled\", \"r\") as ins:\n",
    "    for line in ins:\n",
    "        parts = line.split()\n",
    "        ip_port_src = parts[4].split(':')    \n",
    "        ip_src = ip_port_src[0]\n",
    "        if ip_src == infected:\n",
    "            ip_port_dst = parts[6].split(':')\n",
    "            ip_dst = ip_port_dst[0]\n",
    "            if not ip_dst in ips:\n",
    "                ips[ip_dst] = 0\n",
    "            ips[ip_dst] += 1\n",
    "            infected_flow_count += 1\n",
    "\n",
    "ips_ip = np.array(list(ips.keys()))\n",
    "ips_count = np.array(list(ips.values()))\n",
    "\n",
    "# keep the top 10 IPs\n",
    "ind = np.argsort(-ips_count)[:n]\n",
    "true = {}\n",
    "true['ips'] = ips_ip[ind]\n",
    "true['freqs'] = ips_count[ind] / infected_flow_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build estimate table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t193.23.181.44\t0.136\t62.80.17.242\t0.136\t193.23.181.44\t0.136\t193.23.181.44\t0.136\n",
      "2\t174.128.246.102\t0.076\t200.143.5.118\t0.136\t209.59.172.38\t0.136\t168.61.70.66\t0.136\n",
      "3\t174.37.196.55\t0.074\t209.59.172.38\t0.136\t174.128.246.102\t0.076\t64.85.60.138\t0.136\n",
      "4\t67.19.72.206\t0.069\t193.23.181.44\t0.136\t204.11.209.99\t0.076\t83.238.197.86\t0.076\n",
      "5\t72.20.15.61\t0.066\t174.128.246.102\t0.076\t174.37.196.55\t0.074\t200.42.208.2\t0.076\n",
      "6\t173.236.31.226\t0.038\t204.11.209.99\t0.076\t67.69.240.18\t0.074\t174.128.246.102\t0.076\n",
      "7\t184.154.89.154\t0.037\t64.182.71.51\t0.076\t67.19.72.206\t0.069\t174.37.196.55\t0.074\n",
      "8\t46.4.36.120\t0.036\t130.220.2.1\t0.076\t63.209.10.244\t0.069\t95.172.94.59\t0.074\n",
      "9\t147.32.80.9\t0.017\t85.158.228.111\t0.074\t72.20.15.61\t0.066\t66.210.5.50\t0.074\n",
      "10\t217.163.21.37\t0.015\t174.37.196.55\t0.074\t209.223.88.11\t0.066\t74.125.232.199\t0.069\n"
     ]
    }
   ],
   "source": [
    "for i in range(n):\n",
    "    line = [i+1, true['ips'][i], round(true['freqs'][i],3)]\n",
    "    for j,k in enumerate(ws):\n",
    "        line.append(estimates[j]['ips'][-i-1])\n",
    "        line.append(round(estimates[j]['freqs'][-i-1],3))\n",
    "    print(\"\\t\".join([str(x) for x in line]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "freq_distance measures the distance between the frequencies in the \n",
    "ground-truth list and the frequencies in an estimated list.\n",
    "\n",
    "true, estimate: objects with two list .ips and .freqs\n",
    "'''\n",
    "def freq_distance(true, estimate):\n",
    "    estimate_map = {}\n",
    "    for i, ip in enumerate(estimate['ips']):\n",
    "        estimate_map[ip] = estimate['freqs'][i]\n",
    "    \n",
    "    score = 0\n",
    "    for i, ip in enumerate(true['ips']):\n",
    "        if ip in estimate_map:\n",
    "            score += abs(true['freqs'][i] - estimate_map[ip])\n",
    "        else:\n",
    "            score += true['freqs'][i]\n",
    "    return score   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 50)\t0.3\t0.2791\t7.416\n",
      "(1000, 200)\t0.5\t0.1451\t13.488\n",
      "(700, 25)\t0.3\t0.2791\t6.588\n"
     ]
    }
   ],
   "source": [
    "# create output for recall table\n",
    "for j in range(len(estimates)):\n",
    "    recall = float(len(np.intersect1d(true['ips'], estimates[j]['ips']))) / float(n)\n",
    "    freq_score = freq_distance(true, estimates[j])\n",
    "    run_time = round(np.mean(run_times,axis=0)[j],3)\n",
    "    print(\"{}\\t{}\\t{}\\t{}\".format((ws[j],ds[j]), recall, round(freq_score,4),run_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
